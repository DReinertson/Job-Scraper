7/7/18
	- Thinking about the Web scraper. Had conversation with Eric not fully understanding the point of doing it. He mentioned the idea of using the webscraper one day and finding a way to check if there were new posts between days (i.e. making list that shows only new posts or using the scraper to organize via date posted?)
	- Another thing I was thinking of would be to access the job sites API in order to retrieve entire list of job postings (1000+ per search) and use the job scraper on that instea of doing it page by page. Going to see what the API looks like for flexjobs. 
	- Wondering if it would be more effective to create an object with each variable as a key and use that to create scraped data or put it all into a list. OR! not even making a list or object and using forloop to directly create output. If I were to use Object, wouldn't be able to organize by date posted? If I were to change the month into a number, I could sort properly (If each post was in a list with each variable) based upon the month and post it that way? Maybe even update the list or create another variable to store the sorted version.
	**Made dates into numbers, will create function that sorts the final job_listing variable based upon the date posted and use this for the final excel/webpage post. 
	- Removed html tags from each of the lists. And will use regex to remove spaces from date to sort it and sort job_list at the end using either itemgetter or Lambda (If using lambda, will have to look into documentation of it to understand what it is). 
	- Once I figure out how to sort everything, I will use for loop to go through list of webpages (Each page for the searched criteria) and sort all of this data
	- When sorted I will need to figure out a  way to highlight or show which job posts are new from day to day.
